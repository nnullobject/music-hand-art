<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <title>Gemini Nebula - V3 Visibility</title>
    <style>
        body { margin: 0; overflow: hidden; background: #000; font-family: 'Segoe UI', sans-serif; }
        #ui { position: absolute; top: 30px; left: 30px; color: #fff; pointer-events: none; z-index: 10; }
        h1 { margin: 0; font-weight: 100; letter-spacing: 5px; font-size: 20px; color: #00f2ff; text-transform: uppercase; }
        .status-box { background: rgba(0,0,0,0.5); padding: 12px; border: 1px solid rgba(0,242,255,0.3); border-radius: 4px; margin-top: 10px; backdrop-filter: blur(8px); }
        p { margin: 4px 0; font-size: 13px; color: #00f2ff; opacity: 0.8; }
        canvas { display: block; }
    </style>
</head>
<body>
    <div id="ui">
        <h1>Gemini Visualizer / V3</h1>
        <div class="status-box">
            <p>狀態：<span id="status">點擊螢幕啟動</span></p>
            <p>手勢：<span id="hand-pos">等待偵測...</span></p>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/three@0.150.0/build/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>

    <script id="vertexShader" type="x-shader/x-vertex">
        uniform float uTime;
        uniform float uAudioHigh;
        uniform vec3 uHandPos;
        attribute float aSize;
        attribute float aIndex;
        varying vec3 vColor;
        varying float vAlpha;

        float hash(float n) { return fract(sin(n) * 43758.5453123); }

        void main() {
            // 1. 幾何空間配置 - 讓結構更舒展
            float u = (aIndex / 50000.0) * 6.28318;
            float t = uTime * 0.2;
            
            // 增加隨機偏移量，避免變成厚實的「甜甜圈」
            float shift = hash(aIndex) * 2.5; 
            float v = (sin(t + u * 2.0) + shift) * 1.8;

            vec3 targetPos;
            targetPos.x = cos(u) * (6.0 + v * cos(u * 0.5));
            targetPos.y = sin(u) * (6.0 + v * cos(u * 0.5));
            targetPos.z = v * sin(u * 0.5);

            // 2. 手勢引力與音頻爆炸
            float dist = distance(targetPos, uHandPos);
            // 修正引力：讓它在 4.0 距離內產生明顯吸引
            float attraction = smoothstep(4.0, 0.0, dist) * 3.5;
            vec3 dir = normalize(uHandPos - targetPos);
            
            // 即使沒音樂也有基礎律動感 (0.05)
            float audioEffect = max(uAudioHigh, 0.05);
            vec3 finalPos = targetPos + (dir * attraction) + (normalize(targetPos) * audioEffect * hash(aIndex + 5.0) * 2.5);

            // 3. 渲染配置
            vec4 mvPosition = modelViewMatrix * vec4(finalPos, 1.0);
            
            // 【重要修復】調大基礎尺寸 (120 -> 350)，確保在所有螢幕都可見
            gl_PointSize = aSize * (350.0 / -mvPosition.z) * (1.0 + audioEffect * 2.0);
            gl_Position = projectionMatrix * mvPosition;
            
            // 4. 色彩增益 - 讓顏色更亮
            float colorMap = (finalPos.z + 2.0) / 4.0;
            vColor = mix(vec3(0.0, 0.5, 1.0), vec3(1.0, 0.2, 0.8), colorMap);
            vColor += audioEffect * 0.6; // 音頻亮感
            vAlpha = smoothstep(-15.0, -2.0, mvPosition.z); // 距離遠的粒子變透明
        }
    </script>

    <script id="fragmentShader" type="x-shader/x-fragment">
        varying vec3 vColor;
        varying float vAlpha;
        void main() {
            float dist = length(gl_PointCoord - vec2(0.5));
            // 粒子邊緣過渡調整，保留粒子感的同時增加核心亮度
            float strength = smoothstep(0.5, 0.1, dist);
            if (strength < 0.01) discard;
            gl_FragColor = vec4(vColor, strength * vAlpha * 0.9);
        }
    </script>

    <script>
        let scene, camera, renderer, particles;
        let audioAnalyser, dataArray;
        const handPos = new THREE.Vector3(50, 50, 50); // 初始避開視野中心

        async function init() {
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
            camera.position.z = 15; // 相機後移，視角更廣

            renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2)); // 效能與清晰度平衡
            renderer.setClearColor(0x000005, 1);
            document.body.appendChild(renderer.domElement);

            const count = 50000;
            const geometry = new THREE.BufferGeometry();
            const positions = new Float32Array(count * 3);
            const sizes = new Float32Array(count);
            const indices = new Float32Array(count);

            for (let i = 0; i < count; i++) {
                indices[i] = i;
                sizes[i] = Math.random() * 1.2 + 0.4;
            }

            geometry.setAttribute('position', new THREE.BufferAttribute(positions, 3));
            geometry.setAttribute('aSize', new THREE.BufferAttribute(sizes, 1));
            geometry.setAttribute('aIndex', new THREE.BufferAttribute(indices, 1));

            const material = new THREE.ShaderMaterial({
                uniforms: {
                    uTime: { value: 0 },
                    uAudioHigh: { value: 0 },
                    uHandPos: { value: handPos }
                },
                vertexShader: document.getElementById('vertexShader').textContent,
                fragmentShader: document.getElementById('fragmentShader').textContent,
                transparent: true,
                blending: THREE.AdditiveBlending,
                depthWrite: false
            });

            particles = new THREE.Points(geometry, material);
            scene.add(particles);

            // MediaPipe 手勢初始化
            const hands = new Hands({
                locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
            });
            hands.setOptions({ maxNumHands: 1, modelComplexity: 1, minDetectionConfidence: 0.5 });
            hands.onResults(onHandResults);

            const videoElement = document.createElement('video');
            const cameraUtils = new Camera(videoElement, {
                onFrame: async () => { await hands.send({image: videoElement}); },
                width: 640, height: 480
            });
            cameraUtils.start().catch(() => { document.getElementById('status').innerText = '請開啟攝影機權限'; });

            window.addEventListener('resize', onWindowResize);
            window.onclick = initAudio;
            
            animate();
        }

        function onHandResults(results) {
            if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
                const landmark = results.multiHandLandmarks[0][8]; 
                // 擴大映射範圍
                handPos.x = (landmark.x - 0.5) * -25;
                handPos.y = (0.5 - landmark.y) * 20;
                handPos.z = landmark.z * -15; 
                document.getElementById('hand-pos').innerText = `已捕捉手勢`;
            } else {
                // 沒偵測到時，緩慢飄向角落
                handPos.lerp(new THREE.Vector3(50, 50, 50), 0.05);
                document.getElementById('hand-pos').innerText = `等待手勢中...`;
            }
        }

        async function initAudio() {
            if (audioAnalyser) return;
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                const audioCtx = new AudioContext();
                const source = audioCtx.createMediaStreamSource(stream);
                audioAnalyser = audioCtx.createAnalyser();
                audioAnalyser.fftSize = 128;
                source.connect(audioAnalyser);
                dataArray = new Uint8Array(audioAnalyser.frequencyBinCount);
                document.getElementById('status').innerText = '音訊分析中 (請播放音樂)';
            } catch (e) {
                document.getElementById('status').innerText = '請允許麥克風權限';
            }
        }

        function onWindowResize() {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        }

        function animate() {
            requestAnimationFrame(animate);
            const time = performance.now() * 0.001;
            particles.material.uniforms.uTime.value = time;

            if (audioAnalyser) {
                audioAnalyser.getByteFrequencyData(dataArray);
                // 抓取能量較強的高頻段
                particles.material.uniforms.uAudioHigh.value = dataArray[20] / 255.0;
            }

            particles.rotation.y = time * 0.05;
            renderer.render(scene, camera);
        }

        init();
    </script>
</body>
</html>
