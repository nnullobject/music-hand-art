<!DOCTYPE html>
<html lang="zh-TW">
<head>
    <meta charset="UTF-8">
    <title>Gemini 手勢音樂粒子系統</title>
    <style>
        body { margin: 0; overflow: hidden; background: #000; }
        #ui { position: absolute; top: 20px; left: 20px; color: white; font-family: sans-serif; pointer-events: none; }
        canvas { display: block; }
    </style>
</head>
<body>
    <div id="ui">
        <h1>Gemini Music Visualizer</h1>
        <p>狀態：<span id="status">初始化中...</span></p>
        <p>手勢中心：<span id="hand-pos">等待偵測</span></p>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/three@0.150.0/build/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>

    <script id="vertexShader" type="x-shader/x-vertex">
    uniform float uTime;
    uniform float uAudioHigh;
    uniform vec3 uHandPos;
    attribute float aSize;
    attribute vec3 position; // 原始位置
    varying vec3 vColor;

    // 這裡定義一個簡單的偽隨機函數
    float hash(float n) { return fract(sin(n) * 43758.5453123); }

    void main() {
        // 1. 基礎參數計算
        float idx = float(gl_VertexID);
        float t = uTime * 0.2;
        
        // 2. 幾何變換：莫比烏斯環邏輯 (Mobius Strip Influence)
        // 使用粒子索引來決定它在幾何體上的位置
        float u = (idx / 50000.0) * 6.28318; // 0 到 2pi
        float v = sin(t + u) * 1.5;
        
        vec3 targetPos;
        targetPos.x = cos(u) * (2.0 + v * cos(u * 0.5));
        targetPos.y = sin(u) * (2.0 + v * cos(u * 0.5));
        targetPos.z = v * sin(u * 0.5);

        // 3. 加入手勢干擾 (Gesture Interaction)
        // 計算粒子到手部的距離
        float dist = distance(targetPos, uHandPos);
        float attraction = 1.0 / (dist * dist + 0.1);
        
        // 讓粒子在手部周圍產生「黑洞」般的扭曲感
        vec3 dir = normalize(uHandPos - targetPos);
        targetPos += dir * attraction * (uAudioHigh * 2.0 + 0.5);

        // 4. 音頻震動 (Audio Reactivity)
        // 根據高頻數值讓粒子產生微小的量子跳變
        targetPos += vec3(hash(idx), hash(idx+1.0), hash(idx+2.0)) * uAudioHigh * 0.5;

        // 5. 渲染輸出
        vec4 mvPosition = modelViewMatrix * vec4(targetPos, 1.0);
        
        // 讓距離鏡頭越近的粒子越大，且隨音頻閃爍
        gl_PointSize = aSize * (400.0 / -mvPosition.z) * (1.0 + uAudioHigh * 3.0);
        gl_Position = projectionMatrix * mvPosition;
        
        // 顏色邏輯：根據高度與音頻強度改變
        vColor = mix(vec3(0.0, 0.8, 1.0), vec3(1.0, 0.0, 0.5), (targetPos.z + 1.0) * 0.5);
        vColor += uAudioHigh * 0.4; // 音頻越高，顏色越亮
    }
</script>
    </script>

    <script id="fragmentShader" type="x-shader/x-fragment">
        varying vec3 vColor;
        void main() {
            float r = distance(gl_PointCoord, vec2(0.5));
            if (r > 0.5) discard;
            float strength = 1.0 - (r * 2.0);
            gl_FragColor = vec4(vColor, strength);
        }
    </script>

    <script>
        // --- 初始化變數 ---
        let scene, camera, renderer, particles;
        let audioAnalyser, dataArray;
        const handPos = new THREE.Vector3(0, 0, 0);

        async function init() {
            // 1. Three.js 場景設置
            scene = new THREE.Scene();
            camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
            camera.position.z = 5;

            renderer = new THREE.WebGLRenderer({ antialias: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            document.body.appendChild(renderer.domElement);

            // 2. 創建粒子系統 (50,000 個粒子)
            const geometry = new THREE.BufferGeometry();
            const count = 50000;
            const positions = new Float32Array(count * 3);
            const sizes = new Float32Array(count);

            for (let i = 0; i < count * 3; i++) {
                positions[i] = (Math.random() - 0.5) * 10;
            }
            for (let i = 0; i < count; i++) {
                sizes[i] = Math.random() * 2.0;
            }

            geometry.setAttribute('position', new THREE.BufferAttribute(positions, 3));
            geometry.setAttribute('aSize', new THREE.BufferAttribute(sizes, 1));

            const material = new THREE.ShaderMaterial({
                uniforms: {
                    uTime: { value: 0 },
                    uAudioHigh: { value: 0 },
                    uHandPos: { value: handPos }
                },
                vertexShader: document.getElementById('vertexShader').textContent,
                fragmentShader: document.getElementById('fragmentShader').textContent,
                transparent: true,
                blending: THREE.AdditiveBlending
            });

            particles = new THREE.Points(geometry, material);
            scene.add(particles);

            // 3. MediaPipe 手勢初始化
            const hands = new Hands({
                locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
            });
            hands.setOptions({ maxNumHands: 1, modelComplexity: 1, minDetectionConfidence: 0.5 });
            hands.onResults(onHandResults);

            const videoElement = document.createElement('video');
            const cameraUtils = new Camera(videoElement, {
                onFrame: async () => { await hands.send({image: videoElement}); },
                width: 1280, height: 720
            });
            cameraUtils.start();

            // 4. 音頻初始化 (需用戶點擊啟動)
            window.onclick = initAudio;
            document.getElementById('status').innerText = '點擊畫面以啟動音頻分析';
            
            animate();
        }

        function onHandResults(results) {
            if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
                const landmark = results.multiHandLandmarks[0][8]; // 食指尖
                // 座標轉換: MediaPipe (0~1) -> Three.js (-5~5)
                handPos.x = (landmark.x - 0.5) * -10;
                handPos.y = (0.5 - landmark.y) * 10;
                document.getElementById('hand-pos').innerText = `X: ${handPos.x.toFixed(2)} Y: ${handPos.y.toFixed(2)}`;
            }
        }

        async function initAudio() {
            if (audioAnalyser) return;
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            const audioCtx = new AudioContext();
            const source = audioCtx.createMediaStreamSource(stream);
            audioAnalyser = audioCtx.createAnalyser();
            audioAnalyser.fftSize = 256;
            source.connect(audioAnalyser);
            dataArray = new Uint8Array(audioAnalyser.frequencyBinCount);
            document.getElementById('status').innerText = '音頻與手勢已就緒';
        }

        function animate() {
            requestAnimationFrame(animate);
            const time = performance.now() * 0.001;
            particles.material.uniforms.uTime.value = time;

            if (audioAnalyser) {
                audioAnalyser.getByteFrequencyData(dataArray);
                const highFreq = dataArray[20] / 255.0; // 提取特定頻段
                particles.material.uniforms.uAudioHigh.value = highFreq;
            }

            particles.rotation.y = time * 0.05; // 場景緩緩旋轉
            renderer.render(scene, camera);
        }

        init();
    </script>
</body>
</html>
